{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee1ec7a6",
   "metadata": {},
   "source": [
    "# Mitsui LightGBM Inference (No Recency Weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12401603",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q lightgbm numpy pandas polars pyarrow scikit-learn gplearn TA-Lib joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e207a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import zipfile\n",
    "import shutil\n",
    "from datetime import date\n",
    "\n",
    "BUNDLE_ROOT = Path(\"/kaggle/input/mitsui-lightgbm-training-lag1lag4\")\n",
    "if not BUNDLE_ROOT.exists():\n",
    "    raise FileNotFoundError(\"Dataset mitsui-lightgbm-training-lag1lag4 not found\")\n",
    "\n",
    "def _resolve_bundle_root(base: Path) -> Path:\n",
    "    if base.is_file():\n",
    "        extract_dir = Path(\"/kaggle/working/mitsui_lightgbm_bundle\")\n",
    "        extract_dir.mkdir(parents=True, exist_ok=True)\n",
    "        with zipfile.ZipFile(base, \"r\") as zf:\n",
    "            zf.extractall(extract_dir)\n",
    "        base = extract_dir\n",
    "\n",
    "    src_dir = base / \"src\"\n",
    "    if src_dir.exists():\n",
    "        return base\n",
    "\n",
    "    zip_candidates = sorted(base.glob(\"*.zip\"))\n",
    "    if zip_candidates:\n",
    "        extract_dir = Path(\"/kaggle/working/mitsui_lightgbm_bundle\")\n",
    "        extract_dir.mkdir(parents=True, exist_ok=True)\n",
    "        with zipfile.ZipFile(zip_candidates[0], \"r\") as zf:\n",
    "            zf.extractall(extract_dir)\n",
    "        if (extract_dir / \"src\").exists():\n",
    "            return extract_dir\n",
    "        subdirs = [p for p in extract_dir.iterdir() if p.is_dir()]\n",
    "        for candidate in subdirs:\n",
    "            if (candidate / \"src\").exists():\n",
    "                return candidate\n",
    "        raise FileNotFoundError(f\"Extracted bundle missing src directory: {extract_dir}\")\n",
    "\n",
    "    subdirs = [p for p in base.iterdir() if p.is_dir()]\n",
    "    for candidate in subdirs:\n",
    "        if (candidate / \"src\").exists():\n",
    "            return candidate\n",
    "\n",
    "    raise FileNotFoundError(f\"Could not locate src directory under {base}\")\n",
    "\n",
    "def _inject_sys_path(root: Path) -> Path:\n",
    "    src_root = root / \"src\"\n",
    "    if not src_root.exists() and root.name == \"src\":\n",
    "        src_root = root\n",
    "        root = root.parent\n",
    "\n",
    "    candidates = []\n",
    "    if root.exists():\n",
    "        candidates.append(root)\n",
    "    if src_root.exists():\n",
    "        candidates.append(src_root)\n",
    "\n",
    "    for candidate in reversed(candidates):\n",
    "        path_str = str(candidate)\n",
    "        if path_str not in sys.path:\n",
    "            sys.path.insert(0, path_str)\n",
    "    return src_root if src_root.exists() else root\n",
    "\n",
    "BUNDLE_ROOT = _resolve_bundle_root(BUNDLE_ROOT)\n",
    "SRC_ROOT = _inject_sys_path(BUNDLE_ROOT)\n",
    "\n",
    "if not SRC_ROOT.exists():\n",
    "    raise FileNotFoundError(f\"src directory missing under {BUNDLE_ROOT}\")\n",
    "\n",
    "from src import config\n",
    "CONFIG_ROOT = Path(\"/kaggle/input/mitsui-commodity-prediction-challenge\")\n",
    "config.DATA_DIR = CONFIG_ROOT\n",
    "config.TRAIN_PATH = CONFIG_ROOT / \"train.csv\"\n",
    "config.TEST_PATH = CONFIG_ROOT / \"test.csv\"\n",
    "config.TRAIN_LABELS_PATH = CONFIG_ROOT / \"train_labels.csv\"\n",
    "config.TARGET_PAIRS_PATH = CONFIG_ROOT / \"target_pairs.csv\"\n",
    "config.LAGGED_TEST_LABELS_DIR = CONFIG_ROOT / \"lagged_test_labels\"\n",
    "config.OUTPUT_DIR = Path(\"/kaggle/working/artifacts\")\n",
    "config.OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FEATURE_SOURCE = BUNDLE_ROOT / \"artifacts\" / \"features_v2\"\n",
    "FEATURE_DEST = config.OUTPUT_DIR / \"features_v2\"\n",
    "if FEATURE_SOURCE.exists():\n",
    "    FEATURE_DEST.mkdir(parents=True, exist_ok=True)\n",
    "    for item in FEATURE_SOURCE.iterdir():\n",
    "        dest = FEATURE_DEST / item.name\n",
    "        if item.is_dir():\n",
    "            shutil.copytree(item, dest, dirs_exist_ok=True)\n",
    "        elif item.is_file():\n",
    "            shutil.copy2(item, dest)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Feature artifacts missing: {FEATURE_SOURCE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c352cf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from typing import Dict\n",
    "\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "from src.data.cleaning import fill_dataframe_with_trend\n",
    "from src.data.loading import load_price_data\n",
    "from src.features.online import compute_latest_features, load_online_context\n",
    "\n",
    "\n",
    "class _SilentLogger:\n",
    "    def info(self, msg: str) -> None:\n",
    "        pass\n",
    "    def warning(self, msg: str) -> None:\n",
    "        pass\n",
    "\n",
    "lgb.register_logger(_SilentLogger())\n",
    "\n",
    "ARTIFACT_ROOT = Path(\"/kaggle/working/mitsui_lightgbm_bundle\") / \"artifacts\" / \"lightgbm_full\"\n",
    "if not ARTIFACT_ROOT.exists():\n",
    "    ARTIFACT_ROOT = BUNDLE_ROOT / \"artifacts\" / \"lightgbm_full\"\n",
    "\n",
    "NUM_TARGETS = 424\n",
    "OFFLINE_EVAL_START_DATE_ID = 1827\n",
    "COMPETITION_GO_LIVE_DATE = date(2025, 10, 7)\n",
    "PRECOMPUTED_MIN_DATE_ID = None\n",
    "PRECOMPUTED_MAX_DATE_ID = None\n",
    "\n",
    "\n",
    "def _load_precomputed_panel() -> pd.DataFrame | None:\n",
    "    panel_candidates = [\n",
    "        config.OUTPUT_DIR / \"features_v2\" / \"all_train.parquet\",\n",
    "        config.OUTPUT_DIR / \"features_v2\" / \"all_train.pkl\",\n",
    "        config.OUTPUT_DIR / \"features_v2\" / \"all.pkl\",\n",
    "        config.OUTPUT_DIR / \"features_v2\" / \"all_test.pkl\",\n",
    "    ]\n",
    "    for candidate in panel_candidates:\n",
    "        if candidate.exists():\n",
    "            if candidate.suffix == \".parquet\":\n",
    "                panel = pd.read_parquet(candidate)\n",
    "            else:\n",
    "                panel = pd.read_pickle(candidate)\n",
    "            if not panel.empty:\n",
    "                panel.index = panel.index.astype(int)\n",
    "                panel = panel[panel.index >= OFFLINE_EVAL_START_DATE_ID]\n",
    "                return panel.sort_index()\n",
    "    return None\n",
    "\n",
    "\n",
    "PRECOMPUTED_PANEL = _load_precomputed_panel()\n",
    "if PRECOMPUTED_PANEL is not None:\n",
    "    PRECOMPUTED_PANEL.index = PRECOMPUTED_PANEL.index.astype(int)\n",
    "    PRECOMPUTED_PANEL = PRECOMPUTED_PANEL.sort_index()\n",
    "    PRECOMPUTED_MIN_DATE_ID = int(PRECOMPUTED_PANEL.index.min())\n",
    "    PRECOMPUTED_MAX_DATE_ID = int(PRECOMPUTED_PANEL.index.max())\n",
    "USE_PRECOMPUTED_PANEL = PRECOMPUTED_PANEL is not None\n",
    "\n",
    "context = None\n",
    "price_history_df = None\n",
    "\n",
    "\n",
    "def _ensure_online_state() -> None:\n",
    "    global context, price_history_df\n",
    "    if context is None or price_history_df is None:\n",
    "        context = load_online_context()\n",
    "        price_history_df = load_price_data(\"train\").drop_duplicates(subset='date_id', keep='last').sort_values('date_id')\n",
    "        price_history_df = fill_dataframe_with_trend(price_history_df, window=5, skip_columns=['date_id', 'is_scored'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3d21d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _latest_run_dir(lag: int) -> Path:\n",
    "    runs = sorted((ARTIFACT_ROOT / f\"lag_{lag}\").iterdir(), key=lambda p: p.stat().st_mtime)\n",
    "    if not runs:\n",
    "        raise FileNotFoundError(f\"No trained runs found for lag {lag}\")\n",
    "    return runs[-1]\n",
    "\n",
    "\n",
    "def _load_models() -> Dict[int, Dict[str, lgb.Booster]]:\n",
    "    boosters: Dict[int, Dict[str, lgb.Booster]] = {}\n",
    "    for lag in range(1, 5):\n",
    "        run_dir = _latest_run_dir(lag)\n",
    "        model_dir = run_dir / \"models\"\n",
    "        boosters[lag] = {}\n",
    "        for model_path in sorted(model_dir.glob(\"target_*.txt\")):\n",
    "            boosters[lag][model_path.stem] = lgb.Booster(model_file=str(model_path))\n",
    "    return boosters\n",
    "\n",
    "\n",
    "def _load_preprocessors() -> Dict[int, Dict[str, Dict[str, float] | list[str]]]:\n",
    "    preprocessors: Dict[int, Dict[str, Dict[str, float] | list[str]]] = {}\n",
    "    for lag in range(1, 5):\n",
    "        run_dir = _latest_run_dir(lag)\n",
    "        prep_dir = run_dir / \"preprocessing\"\n",
    "        sample_file = next(prep_dir.glob(\"target_*.json\"))\n",
    "        payload = json.loads(sample_file.read_text())\n",
    "        preprocessors[lag] = {\n",
    "            \"feature_names\": payload[\"feature_names\"],\n",
    "            \"median\": payload[\"median\"],\n",
    "        }\n",
    "    return preprocessors\n",
    "\n",
    "\n",
    "BOOSTERS = _load_models()\n",
    "PREPROCESSORS = _load_preprocessors()\n",
    "TARGETS_BY_LAG = {lag: sorted(models.keys()) for lag, models in BOOSTERS.items()}\n",
    "ALL_TARGETS = sorted({t for names in TARGETS_BY_LAG.values() for t in names})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab59b09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _prepare_features(lag: int, feature_row: pd.DataFrame) -> pd.DataFrame:\n",
    "    names = PREPROCESSORS[lag][\"feature_names\"]\n",
    "    medians = PREPROCESSORS[lag][\"median\"]\n",
    "    aligned = feature_row.reindex(columns=names)\n",
    "    aligned = aligned.fillna(medians)\n",
    "    return aligned\n",
    "\n",
    "\n",
    "def _predict_lag(lag: int, features: pd.DataFrame) -> Dict[str, float]:\n",
    "    models = BOOSTERS[lag]\n",
    "    feature_array = features.to_numpy(dtype=np.float32, copy=False)\n",
    "    outputs: Dict[str, float] = {}\n",
    "    for target, booster in models.items():\n",
    "        value = booster.predict(feature_array, num_iteration=booster.best_iteration)[0]\n",
    "        outputs[target] = float(value)\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622d99f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test: pl.DataFrame,\n",
    "            label_lags_1_batch: pl.DataFrame,\n",
    "            label_lags_2_batch: pl.DataFrame,\n",
    "            label_lags_3_batch: pl.DataFrame,\n",
    "            label_lags_4_batch: pl.DataFrame) -> pd.DataFrame:\n",
    "    global price_history_df, PRECOMPUTED_PANEL, USE_PRECOMPUTED_PANEL, context\n",
    "\n",
    "    test_pdf = test.to_pandas()\n",
    "    latest_date = int(test_pdf['date_id'].max())\n",
    "\n",
    "    feature_row = None\n",
    "    if USE_PRECOMPUTED_PANEL and PRECOMPUTED_PANEL is not None:\n",
    "        if latest_date in PRECOMPUTED_PANEL.index:\n",
    "            feature_row = PRECOMPUTED_PANEL.loc[[latest_date]]\n",
    "        else:\n",
    "            USE_PRECOMPUTED_PANEL = False\n",
    "            PRECOMPUTED_PANEL = None\n",
    "\n",
    "    if feature_row is None:\n",
    "        _ensure_online_state()\n",
    "        price_history_df = pd.concat([price_history_df, test_pdf], ignore_index=True)\n",
    "        price_history_df = fill_dataframe_with_trend(price_history_df, window=5, skip_columns=['date_id', 'is_scored'])\n",
    "        price_history_df = price_history_df.drop_duplicates(subset='date_id', keep='last').sort_values('date_id')\n",
    "        feature_row = compute_latest_features(price_history_df, context)\n",
    "\n",
    "    outputs: Dict[str, float] = {target: 0.0 for target in ALL_TARGETS}\n",
    "    for lag in range(1, 5):\n",
    "        feats = _prepare_features(lag, feature_row)\n",
    "        preds = _predict_lag(lag, feats)\n",
    "        outputs.update(preds)\n",
    "\n",
    "    row = [outputs[target] for target in ALL_TARGETS]\n",
    "    return pd.DataFrame([row], columns=ALL_TARGETS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453c734d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle_evaluation.mitsui_inference_server\n",
    "\n",
    "def _run_server() -> None:\n",
    "    data_paths = ('/kaggle/input/mitsui-commodity-prediction-challenge/',)\n",
    "    inference_server = kaggle_evaluation.mitsui_inference_server.MitsuiInferenceServer(predict)\n",
    "    if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "        inference_server.serve()\n",
    "    else:\n",
    "        inference_server.run_local_gateway(data_paths)\n",
    "\n",
    "_run_server()\n",
    "\n",
    "submission_path = Path('submission.parquet')\n",
    "if not submission_path.exists():\n",
    "    placeholder = pd.DataFrame({name: [0.0] for name in ALL_TARGETS})\n",
    "    placeholder.to_parquet(submission_path, index=False)\n",
    "    print('Wrote placeholder submission to', submission_path)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}